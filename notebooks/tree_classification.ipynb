{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/iu5git/Deep-learning/blob/main/notebooks/tree_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpsOBMUGgYjD"
   },
   "source": [
    "# Лабораторная работа\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Задание\n",
    "\n",
    "Обучите модель нейронной сети для классификации пород деревьев, используя файлы облака точек.\n",
    "\n",
    "Отчет должен содержать: титульный лист, задание с вариантом, скриншоты и краткие пояснения по каждому этапу лабораторной работы, итоговую таблицу со результатами для всех вариантов обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Задания для самостоятельной работы\n",
    "\n",
    "1. Укажите файл по вашему варианту и измените список классов, которые относятся к вашему варианту. Обучите модель\n",
    "2. Измените гиперпараметры обучения для улучшения модели: количество эпох, размер батча, скорость обучения\n",
    "3. Укажите, какие действия помогли улучшить метрики ваших моделей и объясните почему."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Контрольные вопросы для защиты\n",
    "\n",
    "1. Архитектура PointNet\n",
    "2. Что такое плотное облако точек? Форматы представления\n",
    "3. Размер карты признаков и количество каналов в PointNet\n",
    "4. В PointNet используются какие слои CNN или MLP? \n",
    "5. Самостоятельно посчитать по Confusion Matrix: Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSmZDQ1xiLtD"
   },
   "source": [
    "## Теория\n",
    "\n",
    "Облако точек - это самый простой способ представления различных объектов в виде неупорядоченного набора точек в трехмерной плоскости. Такие данные можно получить с помощью сканирования предметов или их структуры с помощью 3D-датчиков, например LiDAR. Качественные облака точек с высокой точностью измерения позволяют представить цифровую версию реального мира.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://www.codeproject.com/KB/openGL/839389/bunny_points.PNG' />\n",
    "<figcaption>Стэндфордский кролик</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Как правило, при глубоком обучении трехмерного облака точек необходимо решить две задачи: классификацию и сегментацию.\n",
    "Основная проблема работы с облаком точек заключается в том, что типичная сверточная архитектура требует упорядоченный формат входных данных (например, изображение). Поскольку облако точек не является таким, общепринятые подходы заключаются в преобразовании данных в обычную 3D-воксельную сетку или проекцию.\n",
    "\n",
    "В данной лабораторной работе используется архитектура PointNet. Эта модель использует неупорядоченные облака точек и может выполнять классификацию и сегментацию объектов, а также семантический анализ сцены.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='http://stanford.edu/~rqi/pointnet/images/teaser.jpg' />\n",
    "<figcaption>Применение PointNet</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "В сети есть 3 ключевых модуля: слой Max Pooling, принимающий n векторов входных данных и выводящий новый вектор, две сети трансформации с многослойным персептроном (MLP) с размерами (64,64) и (64,128,1024) и две сети для предсказания с обученной матрицей преобразования T-Net.\n",
    "\n",
    "PointNet изучает характеристики индивидуальной точки с помощью MLP и объединяет все их характеристики с помощью симметричной функции для выполнения классификации объектов и их сегментации на части. \n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='http://stanford.edu/~rqi/pointnet/images/pointnet.jpg' />\n",
    "<figcaption>Архитектура PointNet</figcaption></center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaFo0Hz9hGG2"
   },
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzXctZ3SFxMo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import regularizers\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy3i39KThRrf"
   },
   "source": [
    "## Загрузка набора данных\n",
    "\n",
    "Для выполнения лабораторной работы необходимо скачать файл формата h5 из репозитория `GitHub`. Поскольку каждая точка одного облака точек содержит информацию о 3 различных координатах, данный формат удобен для хранения и работы с таким большим объемом данных.\n",
    "\n",
    "Файл выбирается следующим образом:\n",
    "\n",
    "v1 - нечетный вариант, v2 - четный вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mnu1zLxOF56T"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2v-oxqBF8T0"
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File(os.path.join(DATA_DIR, \"v1.h5\"),'r') # файл по вашему варианту\n",
    "X = h5f.get('dataset_X')[:]\n",
    "Y = h5f.get('dataset_Y').asstr()[:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9kBFALXGM5f"
   },
   "outputs": [],
   "source": [
    "NUM_POINTS = 4096\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Укажите классы по варианту из вашего файла\n",
    "CLASSES = {\n",
    "    0:'Рябина', \n",
    "    1:'Ель', \n",
    "    2:'Сосна', \n",
    "    3:'Дуб',\n",
    "    4:'Береза'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6du8biS_oSXH"
   },
   "outputs": [],
   "source": [
    "Y = np.array([list(CLASSES.values()).index(y) for y in Y])\n",
    "indexes = []\n",
    "[indexes.append(y) for y in list(Y) if y not in indexes]\n",
    "indexes.sort()\n",
    "CLASS_MAP = {i: CLASSES[k] for (k, i) in (zip(indexes, range(len(indexes))))}\n",
    "\n",
    "#кол-во классов по вашему варианту\n",
    "NUM_CLASSES = len(CLASS_MAP)\n",
    "\n",
    "for (k, i) in (zip(indexes, range(len(indexes)))):\n",
    "  Y[Y == k] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myo5gyyzjGf_"
   },
   "outputs": [],
   "source": [
    "points = X[50]\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_q-IBner6O_"
   },
   "outputs": [],
   "source": [
    "data = {'Кол-во деревьев': list(pd.value_counts(Y).sort_index()),\n",
    "        'Деревья': list(CLASS_MAP.values())}\n",
    "df = pd.DataFrame(data).set_index('Деревья')\n",
    "ax = df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWor6G15h-eb"
   },
   "source": [
    "## Разбиение выборки на тренировочную и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLkdiCvMHy7m"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5).split(X, Y)\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "X_augment = []\n",
    "y_augment = []\n",
    "\n",
    "for i in range(4):\n",
    "    point_select = []\n",
    "    for x in X_train:\n",
    "        idx = np.random.choice(NUM_POINTS, size=NUM_POINTS, replace=True)\n",
    "        point_select.append(x[idx])\n",
    "    point_select = np.array(point_select)        \n",
    "    point_select = point_select + np.random.normal(0, 0.005, point_select.shape)\n",
    "    X_augment.append(point_select)\n",
    "    y_augment.append(y_train)\n",
    "\n",
    "X_augment = np.array(X_augment)\n",
    "y_augment = np.array(y_augment)\n",
    "X_augment = np.reshape(X_augment,(X_augment.shape[0] * X_augment.shape[1], NUM_POINTS, 3))\n",
    "y_augment = np.reshape(y_augment,(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwVpeG2DlBsz"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_augment, y_augment))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(len(X_augment)).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.shuffle(len(X_test)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zf9mbCHkhl-S"
   },
   "source": [
    "## Построение модели\n",
    "\n",
    "Каждый сверточный и полносвязный слой (не включая конечных слоев) состоит из Convolution / Dense -> Batch Normalization -> ReLU Activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkfkKcYMIVKG"
   },
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcVm4reEW7K2"
   },
   "source": [
    "PointNet состоит из двух основных компонентов: основная сеть MLP (многослойный перцептрон) и трансформаторная сеть T-net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mPCuwVhlJhX"
   },
   "outputs": [],
   "source": [
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALXzk7HgXPJ-"
   },
   "source": [
    "Определим общую функцию для построения слоев T-net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfwJxKszlN9x"
   },
   "outputs": [],
   "source": [
    "def tnet(inputs, num_features):\n",
    "\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    \n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBHNLL5OlQOz"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
    "\n",
    "x = tnet(inputs, 3)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 128)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obG5XF57igJY"
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z84IF1Z2ilf1"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDOuMD_Min_2"
   },
   "source": [
    "## Визуализация результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QnsXT6ryldeR"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cc1VzgsFl2u2"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRijfqB-l5iw"
   },
   "outputs": [],
   "source": [
    "data = test_dataset.take(1)\n",
    "\n",
    "points, labels = list(data)[0]\n",
    "points = points[:8, ...]\n",
    "labels = labels[:8, ...]\n",
    "\n",
    "preds = model.predict(points)\n",
    "preds = tf.math.argmax(preds, -1)\n",
    "\n",
    "points = points.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(4, 2, i + 1, projection=\"3d\")\n",
    "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n",
    "    ax.set_title(\n",
    "        \"pred: {:}, label: {:}\".format(\n",
    "            CLASS_MAP[preds[i].numpy()], CLASS_MAP[labels.numpy()[i]]\n",
    "        )\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Db4c9RFrmHMV"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfP5nerImBc3"
   },
   "outputs": [],
   "source": [
    "data = test_dataset.take(1)\n",
    "points, labels = list(data)[0]\n",
    "points = points[:, ...]\n",
    "labels = labels[:, ...]\n",
    "\n",
    "preds = model.predict(points)\n",
    "preds = tf.math.argmax(preds, -1)\n",
    "\n",
    "cm = confusion_matrix(y_true=labels, y_pred=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWuxFwhhmJTE"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=CLASS_MAP.values(), title='Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
